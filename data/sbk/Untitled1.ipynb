{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2019 08 07\n",
    "RNN 실습하기 - 영화리뷰 실습하기\n",
    "\"\"\"\n",
    "\n",
    "#### 데이터 전처리\n",
    "import re\n",
    "import konlpy\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "train_data = pd.read_table('./data/ratings_train.txt')\n",
    "test_data = pd.read_table('./data/ratings_test.txt')\n",
    "\n",
    "# null 값 제거\n",
    "train_data = train_data.dropna(how='any')\n",
    "test_data = test_data.dropna(how='any')\n",
    "\n",
    "# 알파벳, 공백 제외\n",
    "rgexp = '[^ㄱ-ㅎㅏ-ㅣ가-힣 ]'\n",
    "train_data['document'] = train_data['document'].str.replace(rgexp,'')\n",
    "test_data['document'] = test_data['document'].str.replace(rgexp,'')\n",
    "\n",
    "print(train_data['document'])\n",
    "# 불용어(조사, 어미 , 접속사) 제거\n",
    "stopwords = ['의','가','이','은','들','는','좀','과','도','를','으로','에','와']\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "x_train=[]\n",
    "for sentence in train_data['document']: #15만번 반복\n",
    "    temp_x = []\n",
    "    temp_x = okt.morphs(sentence, stem=True)\n",
    "    temp_x = [word for word in temp_x if not word in stopwords]\n",
    "    x_train.append(temp_x)\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_train[1])\n",
    "print(x_train[2])\n",
    "print(x_train[3])\n",
    "print(x_train[4])\n",
    "\n",
    "x_test=[]\n",
    "for sentence in test_data['document']: #15만번 반복\n",
    "    temp_x = []\n",
    "    temp_x = okt.morphs(sentence, stem=True)\n",
    "    temp_x = [word for word in temp_x if not word in stopwords]\n",
    "    x_test.append(temp_x)\n",
    "\n",
    "print(x_test[0])\n",
    "print(x_test[1])\n",
    "print(x_test[2])\n",
    "print(x_test[3])\n",
    "print(x_test[4])\n",
    "\n",
    "# 텍스트 단어 부호화(정수 인코딩)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=30000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "\n",
    "#### 딥러닝\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 데이터 준비\n",
    "train_label = train_data['label']\n",
    "test_label = test_data['label']\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = pad_sequences(x_train,maxlen=30)\n",
    "x_test = pad_sequences(x_test,maxlen=30)\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(30000,100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 설정\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_train,\n",
    "          train_label,\n",
    "          epochs=3,\n",
    "          batch_size=60,\n",
    "          validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "result = model.evaluate(x_test, test_label)\n",
    "print('loss =', result[0])\n",
    "print('accuracy=', result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python36864bitvenvvenvd496da48ae144fa9baf782505b2a856e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
